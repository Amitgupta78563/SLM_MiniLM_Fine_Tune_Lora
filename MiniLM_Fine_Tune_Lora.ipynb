{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6b810a30-a6e7-4b63-93ce-ce5bb3eaa296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f078ce40-9c94-454e-9363-3e03a1def5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.2.2\n",
      "Transformers: 4.49.0\n",
      "Accelerate: 1.4.0\n",
      "Huggingface Hub: 0.29.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import accelerate\n",
    "import huggingface_hub\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Accelerate:\", accelerate.__version__)\n",
    "print(\"Huggingface Hub:\", huggingface_hub.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2b7400-d397-4a93-961a-aee16def8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ba2e6e-3b00-46e1-b640-664e054a2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"balanced_512.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb49e52-67ab-424f-a962-2bc62b4bcd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_area\n",
       "Warranty                     86\n",
       "Shopping                     86\n",
       "Shipping                     85\n",
       "Login and Account            85\n",
       "Order                        85\n",
       "Cancellations and returns    85\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90d0293-c13d-490f-81bf-ba197d5aa5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_area</th>\n",
       "      <th>issue_category</th>\n",
       "      <th>issue_sub_category</th>\n",
       "      <th>issue_category_sub_category</th>\n",
       "      <th>customer_sentiment</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>issue_complexity</th>\n",
       "      <th>agent_experience_level</th>\n",
       "      <th>agent_experience_level_desc</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shipping</td>\n",
       "      <td>Free Delivery Qualification</td>\n",
       "      <td>Reasons for an order not qualifying for free d...</td>\n",
       "      <td>Free Delivery Qualification -&gt; Reasons for an ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Men/Women/Kids</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>medium</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  issue_area               issue_category  \\\n",
       "0   Shipping  Free Delivery Qualification   \n",
       "\n",
       "                                  issue_sub_category  \\\n",
       "0  Reasons for an order not qualifying for free d...   \n",
       "\n",
       "                         issue_category_sub_category customer_sentiment  \\\n",
       "0  Free Delivery Qualification -> Reasons for an ...            neutral   \n",
       "\n",
       "  product_category product_sub_category issue_complexity  \\\n",
       "0   Men/Women/Kids               Diaper           medium   \n",
       "\n",
       "  agent_experience_level                        agent_experience_level_desc  \\\n",
       "0            experienced  confidently handles complex customer issues, e...   \n",
       "\n",
       "                                        conversation  \n",
       "0  Agent: Thank you for calling BrownBox Customer...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1d8c49-d068-4dba-b154-5167f95c591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(conversation):\n",
    "    # Ensure conversation is a list\n",
    "    if isinstance(conversation, list):\n",
    "        return \" \".join([turn.get('text', '') for turn in conversation if isinstance(turn, dict)])\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8370cd50-d7cc-4110-b9bc-0bb408b00e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If conversations are stored as lists of dictionaries\n",
    "if isinstance(df['conversation'].iloc[0], list):\n",
    "    # If conversation is a list of dictionaries, preprocess it\n",
    "    df['Text'] = df['conversation'].apply(preprocess)\n",
    "else:\n",
    "    # If conversation is already plain text, just convert it to string\n",
    "    df['Text'] = df['conversation'].apply(lambda x: str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611e95bc-6517-45f8-8101-b9ceb565ad14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shipping', 'Warranty', 'Login and Account', 'Order', 'Shopping',\n",
       "       'Cancellations and returns'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96eac17-6b30-4cf8-a9af-5b30d48effe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_area\n",
       "Warranty                     86\n",
       "Shopping                     86\n",
       "Shipping                     85\n",
       "Login and Account            85\n",
       "Order                        85\n",
       "Cancellations and returns    85\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e7316fa-d307-4dfb-bc81-4ee2dc6f88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "df['Label'] = df['issue_area'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172d4e91-0bd3-4a5d-af85-1698643da41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 1, 2, 4, 0], dtype=int8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47327ff-1ea7-470f-8235-9962c7b2ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3a0afc-39af-4942-9536-050880ae14df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23d64b9a7244c68921bc8d07c64a461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469933fede9943b2a8842c2d34e089d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe27ab8baab49fd8be69b02110a20f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8616891fa39240efa63f85071f75369b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['Text'], df['Label'], test_size=0.2, random_state=42)\n",
    "model_name = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Update tokenizer max_length if needed\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=256)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=256)\n",
    "\n",
    "\n",
    "train_labels = torch.tensor(train_labels.tolist())\n",
    "test_labels = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fed0d09-7b41-436b-943d-06ef16d923cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b8e22c0-888c-4bcf-aed5-20a331346b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfb630f6e80417599d09ef879d157b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91212803c7ce451b83b522222b5a7f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/MiniLM-L12-H384-uncased\"  # Change model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(df['Label'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b91757f-e6bc-46f4-b0b6-1efbac80a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update LoRA config for increased capacity\n",
    "lora_config = LoraConfig(\n",
    "    r=32,                # Increased rank\n",
    "    lora_alpha=64,       # Increased scaling factor\n",
    "    lora_dropout=0.1,    # Reduced dropout\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"]  # You can experiment with adding \"key\" as well\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ecb8eb2-aa8a-464e-9c83-298bd0b534a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 589824 / Total parameters: 33952134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print trainable vs total parameters to check freezing is in effect\n",
    "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in peft_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params} / Total parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72472cd5-1bd4-45d7-91bc-7a79cd4fed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Setup Training Arguments for CPU\n",
    "# ---------------------------\n",
    "mp.set_start_method(\"fork\", force=True)\n",
    "\n",
    "# Update training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=50,      # Increased epochs\n",
    "    learning_rate=2e-4,       # Lower learning rate\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8cfdf74-b4f6-4884-9255-917a67a7b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    labels = pred.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4910f565-4b6b-45a6-9b71-f7112797b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class WrappedPeftModel(nn.Module):\n",
    "    def __init__(self, peft_model):\n",
    "        super().__init__()\n",
    "        self.peft_model = peft_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "        # Remove unexpected keyword arguments that the underlying model doesn't accept.\n",
    "        kwargs.pop(\"num_items_in_batch\", None)\n",
    "        return self.peft_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, **kwargs)\n",
    "\n",
    "wrapped_model = WrappedPeftModel(peft_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12c833ff-f3b1-48ec-8a07-3db712b23082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TimeCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch_times = []\n",
    "    \n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        # Record the start time of the epoch\n",
    "        self.epoch_start_time = time.time()\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # Compute the duration of the epoch\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {state.epoch:.2f} finished in {epoch_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30bd5858-32fc-4699-bf43-bf22628736fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of your custom callback\n",
    "time_callback = TimeCallback()\n",
    "\n",
    "# Create your Trainer with the callback\n",
    "trainer = Trainer(\n",
    "    model=wrapped_model,  # Use your wrapped model for training\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[time_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50b73846-496a-424d-8da4-634909c2ddb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2600' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2600/2600 36:23, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.793700</td>\n",
       "      <td>1.791569</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.030540</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.051994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.790400</td>\n",
       "      <td>1.791506</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.030540</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.051994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.791500</td>\n",
       "      <td>1.791196</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.030540</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.051994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.783400</td>\n",
       "      <td>1.773955</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.227495</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.213342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.698900</td>\n",
       "      <td>1.710612</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.197619</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.678500</td>\n",
       "      <td>1.701693</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.197619</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.689500</td>\n",
       "      <td>1.674649</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.300798</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.203740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.659000</td>\n",
       "      <td>1.631121</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.315609</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.355298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.589100</td>\n",
       "      <td>1.594028</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.396736</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.422608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.586600</td>\n",
       "      <td>1.583556</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.507282</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.371458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.567300</td>\n",
       "      <td>1.573042</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.499194</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.377591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.569500</td>\n",
       "      <td>1.568758</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.652150</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.445105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.555700</td>\n",
       "      <td>1.569190</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.469435</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.410723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.550100</td>\n",
       "      <td>1.552908</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.634358</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.548914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.529700</td>\n",
       "      <td>1.521619</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.638234</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.642858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.504100</td>\n",
       "      <td>1.494260</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.655783</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.679087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.482500</td>\n",
       "      <td>1.485854</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.849927</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.703518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.437700</td>\n",
       "      <td>1.476224</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.825104</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.743292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.440700</td>\n",
       "      <td>1.458991</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.774918</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.759380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.429400</td>\n",
       "      <td>1.441544</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.862760</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.808237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.412900</td>\n",
       "      <td>1.443530</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.812816</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.777956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.393400</td>\n",
       "      <td>1.426175</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.851148</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.831746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.399600</td>\n",
       "      <td>1.427069</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.852271</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.830478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.384900</td>\n",
       "      <td>1.415999</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.870457</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.852182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.387100</td>\n",
       "      <td>1.407020</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.914982</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.902688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.372700</td>\n",
       "      <td>1.395950</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.907205</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.893993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.357100</td>\n",
       "      <td>1.403675</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.887221</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.872125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.359100</td>\n",
       "      <td>1.399379</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.850955</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.828623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.345000</td>\n",
       "      <td>1.388537</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.884758</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.865732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.323600</td>\n",
       "      <td>1.385248</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.889894</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.873303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.338000</td>\n",
       "      <td>1.380399</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.328800</td>\n",
       "      <td>1.378092</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.905351</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.892641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.334000</td>\n",
       "      <td>1.376047</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.889894</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.873303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.327600</td>\n",
       "      <td>1.371257</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.903179</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.884639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.321500</td>\n",
       "      <td>1.373907</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.881837</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.863456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.319800</td>\n",
       "      <td>1.373610</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.881837</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.863456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.322800</td>\n",
       "      <td>1.371255</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.888716</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.872904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.317300</td>\n",
       "      <td>1.371042</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.889894</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.873303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.319800</td>\n",
       "      <td>1.366016</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.314900</td>\n",
       "      <td>1.365235</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.889894</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.873303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.315800</td>\n",
       "      <td>1.363856</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.314100</td>\n",
       "      <td>1.363423</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.316800</td>\n",
       "      <td>1.359368</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.309600</td>\n",
       "      <td>1.360189</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.313100</td>\n",
       "      <td>1.359885</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.316800</td>\n",
       "      <td>1.358706</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.900035</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.317900</td>\n",
       "      <td>1.359091</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.892279</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.874110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>1.359326</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.897318</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.882867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.308100</td>\n",
       "      <td>1.358613</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.907189</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.893244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.310500</td>\n",
       "      <td>1.358478</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.907189</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.893244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1.00 finished in 19.42 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2.00 finished in 19.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3.00 finished in 19.89 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4.00 finished in 19.60 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5.00 finished in 19.52 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6.00 finished in 20.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7.00 finished in 20.64 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8.00 finished in 20.95 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9.00 finished in 21.62 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10.00 finished in 25.45 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11.00 finished in 27.36 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12.00 finished in 28.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13.00 finished in 29.23 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14.00 finished in 30.99 seconds.\n",
      "Epoch 15.00 finished in 34.35 seconds.\n",
      "Epoch 16.00 finished in 35.68 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17.00 finished in 37.92 seconds.\n",
      "Epoch 18.00 finished in 40.93 seconds.\n",
      "Epoch 19.00 finished in 45.63 seconds.\n",
      "Epoch 20.00 finished in 50.23 seconds.\n",
      "Epoch 21.00 finished in 50.62 seconds.\n",
      "Epoch 22.00 finished in 66.07 seconds.\n",
      "Epoch 23.00 finished in 64.53 seconds.\n",
      "Epoch 24.00 finished in 63.33 seconds.\n",
      "Epoch 25.00 finished in 65.96 seconds.\n",
      "Epoch 26.00 finished in 69.12 seconds.\n",
      "Epoch 27.00 finished in 71.63 seconds.\n",
      "Epoch 28.00 finished in 69.01 seconds.\n",
      "Epoch 29.00 finished in 60.43 seconds.\n",
      "Epoch 30.00 finished in 48.34 seconds.\n",
      "Epoch 31.00 finished in 49.83 seconds.\n",
      "Epoch 32.00 finished in 49.76 seconds.\n",
      "Epoch 33.00 finished in 49.10 seconds.\n",
      "Epoch 34.00 finished in 41.93 seconds.\n",
      "Epoch 35.00 finished in 39.73 seconds.\n",
      "Epoch 36.00 finished in 40.18 seconds.\n",
      "Epoch 37.00 finished in 51.87 seconds.\n",
      "Epoch 38.00 finished in 54.51 seconds.\n",
      "Epoch 39.00 finished in 37.72 seconds.\n",
      "Epoch 40.00 finished in 35.13 seconds.\n",
      "Epoch 41.00 finished in 40.46 seconds.\n",
      "Epoch 42.00 finished in 40.58 seconds.\n",
      "Epoch 43.00 finished in 40.22 seconds.\n",
      "Epoch 44.00 finished in 38.00 seconds.\n",
      "Epoch 45.00 finished in 34.79 seconds.\n",
      "Epoch 46.00 finished in 38.31 seconds.\n",
      "Epoch 47.00 finished in 40.54 seconds.\n",
      "Epoch 48.00 finished in 39.83 seconds.\n",
      "Epoch 49.00 finished in 35.81 seconds.\n",
      "Epoch 50.00 finished in 36.31 seconds.\n",
      "Total Training Time: 2185.23 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        19\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.78      0.78      0.78        18\n",
      "           3       0.75      1.00      0.86        15\n",
      "           4       1.00      0.76      0.87        17\n",
      "           5       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           0.89       103\n",
      "   macro avg       0.91      0.90      0.89       103\n",
      "weighted avg       0.91      0.89      0.89       103\n",
      "\n",
      "Total Accuracy: 89.32%\n"
     ]
    }
   ],
   "source": [
    "# Measure total training time\n",
    "train_start = time.time()\n",
    "trainer.train()\n",
    "total_train_time = time.time() - train_start\n",
    "print(f\"Total Training Time: {total_train_time:.2f} seconds.\")\n",
    "\n",
    " #Evaluate\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(preds_output.predictions), dim=1)\n",
    "\n",
    "print(classification_report(test_labels, preds))\n",
    "\n",
    "\n",
    "# Print overall accuracy as a percentage\n",
    "overall_accuracy = accuracy_score(test_labels, preds)\n",
    "print(\"Total Accuracy: {:.2f}%\".format(overall_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de357f7-d988-4c61-833d-eff3eb8c272e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "108b0d34-1cc5-4a48-aee2-b88d4fc27bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update LoRA config for increased capacity\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                # Increased rank\n",
    "    lora_alpha=32,       # Increased scaling factor\n",
    "    lora_dropout=0.1,    # Reduced dropout\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"]  # You can experiment with adding \"key\" as well\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfcce748-da61-4232-bbf1-fc48c91754d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 147456 / Total parameters: 33509766\n"
     ]
    }
   ],
   "source": [
    "# Print trainable vs total parameters to check freezing is in effect\n",
    "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in peft_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params} / Total parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd55c21f-7e5c-41c2-8d51-b583296b8f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Setup Training Arguments for CPU\n",
    "# ---------------------------\n",
    "mp.set_start_method(\"fork\", force=True)\n",
    "\n",
    "# Update training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=50,      # Increased epochs\n",
    "    learning_rate=2e-4,       # Lower learning rate\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b94892a-83df-41b5-be67-7cf9ef3c643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    labels = pred.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ad2581d-df14-46e9-9242-55fb8d8d5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class WrappedPeftModel(nn.Module):\n",
    "    def __init__(self, peft_model):\n",
    "        super().__init__()\n",
    "        self.peft_model = peft_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "        # Remove unexpected keyword arguments that the underlying model doesn't accept.\n",
    "        kwargs.pop(\"num_items_in_batch\", None)\n",
    "        return self.peft_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, **kwargs)\n",
    "\n",
    "wrapped_model = WrappedPeftModel(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c62fd-a61f-43b8-aa15-490f7ba91c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "632f48c8-cf5a-40ae-a7d5-e4c375722c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TimeCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch_times = []\n",
    "    \n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        # Record the start time of the epoch\n",
    "        self.epoch_start_time = time.time()\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # Compute the duration of the epoch\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {state.epoch:.2f} finished in {epoch_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "573024e7-a15d-4f22-9351-3d8259cd6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of your custom callback\n",
    "time_callback = TimeCallback()\n",
    "\n",
    "# Create your Trainer with the callback\n",
    "trainer = Trainer(\n",
    "    model=wrapped_model,  # Use your wrapped model for training\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[time_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00dc858e-0fe5-427d-a59e-814c0f1f63bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2600' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2600/2600 35:58, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.477249</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.796901</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.759121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.456500</td>\n",
       "      <td>1.472511</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.831706</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.797566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.447500</td>\n",
       "      <td>1.464072</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.806884</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.786313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.467000</td>\n",
       "      <td>1.461899</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.853166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.418500</td>\n",
       "      <td>1.460404</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.798187</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.789823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.431100</td>\n",
       "      <td>1.462578</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.741083</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.735554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.443300</td>\n",
       "      <td>1.439290</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.882648</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.871333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.415900</td>\n",
       "      <td>1.428574</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.855267</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.838427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.407300</td>\n",
       "      <td>1.423483</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.849464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.398700</td>\n",
       "      <td>1.413098</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.883638</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.873417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.391800</td>\n",
       "      <td>1.410083</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.891605</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.881689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.376000</td>\n",
       "      <td>1.408988</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.869682</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.854013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.376100</td>\n",
       "      <td>1.402485</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.370200</td>\n",
       "      <td>1.402552</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.897126</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.883495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.365600</td>\n",
       "      <td>1.391877</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.374200</td>\n",
       "      <td>1.393410</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.902015</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.892243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.358700</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.902015</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.892243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.346300</td>\n",
       "      <td>1.388803</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.912404</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.902509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.358200</td>\n",
       "      <td>1.375540</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>1.376228</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.908474</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.901439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.348400</td>\n",
       "      <td>1.380870</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.893982</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.882469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.340100</td>\n",
       "      <td>1.370449</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.336800</td>\n",
       "      <td>1.372047</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>1.363377</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.909312</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.339200</td>\n",
       "      <td>1.367441</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.892145</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.881866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.334100</td>\n",
       "      <td>1.364233</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.326200</td>\n",
       "      <td>1.366360</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.330200</td>\n",
       "      <td>1.359142</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.324200</td>\n",
       "      <td>1.360152</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.910447</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.901909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>1.355847</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.321800</td>\n",
       "      <td>1.353623</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.322400</td>\n",
       "      <td>1.358181</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>1.354142</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.910447</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.901909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.326600</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.896972</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.884412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.312800</td>\n",
       "      <td>1.352116</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.313700</td>\n",
       "      <td>1.349866</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.314900</td>\n",
       "      <td>1.350335</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.310200</td>\n",
       "      <td>1.353428</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.313100</td>\n",
       "      <td>1.351175</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.910447</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.901909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.308400</td>\n",
       "      <td>1.349267</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.911872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>1.353953</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.308400</td>\n",
       "      <td>1.355116</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.311500</td>\n",
       "      <td>1.355268</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.306200</td>\n",
       "      <td>1.353866</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.310300</td>\n",
       "      <td>1.356661</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.311800</td>\n",
       "      <td>1.353953</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.311200</td>\n",
       "      <td>1.354640</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.307200</td>\n",
       "      <td>1.354951</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.303900</td>\n",
       "      <td>1.353526</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.308300</td>\n",
       "      <td>1.353409</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.891862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Time: 2161.01 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        19\n",
      "           1       0.94      0.83      0.88        18\n",
      "           2       0.78      0.78      0.78        18\n",
      "           3       0.83      1.00      0.91        15\n",
      "           4       1.00      0.76      0.87        17\n",
      "           5       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           0.89       103\n",
      "   macro avg       0.90      0.90      0.89       103\n",
      "weighted avg       0.90      0.89      0.89       103\n",
      "\n",
      "Total Accuracy: 89.32%\n"
     ]
    }
   ],
   "source": [
    "# Measure total training time\n",
    "train_start = time.time()\n",
    "trainer.train()\n",
    "total_train_time = time.time() - train_start\n",
    "print(f\"Total Training Time: {total_train_time:.2f} seconds.\")\n",
    "\n",
    " #Evaluate\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(preds_output.predictions), dim=1)\n",
    "\n",
    "print(classification_report(test_labels, preds))\n",
    "\n",
    "\n",
    "# Print overall accuracy as a percentage\n",
    "overall_accuracy = accuracy_score(test_labels, preds)\n",
    "print(\"Total Accuracy: {:.2f}%\".format(overall_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abfa89-90fe-4ed3-98bd-3180e87f3cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3d20d-c63b-46a1-90bb-6642bbb66552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "400e1b14-f757-47fd-a162-68d59f4fe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the adapter weights and configuration to the specified directory.\n",
    "# peft_model.save_pretrained(\"./exp_4_87_30epc_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38b50b82-6e64-48e6-93a5-bbfadbbf5c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_area</th>\n",
       "      <th>issue_category</th>\n",
       "      <th>issue_sub_category</th>\n",
       "      <th>issue_category_sub_category</th>\n",
       "      <th>customer_sentiment</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>issue_complexity</th>\n",
       "      <th>agent_experience_level</th>\n",
       "      <th>agent_experience_level_desc</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Login and Account</td>\n",
       "      <td>Account Reactivation and Deactivation</td>\n",
       "      <td>Reactivating an inactive account</td>\n",
       "      <td>Account Reactivation and Deactivation -&gt; React...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Microwave Oven</td>\n",
       "      <td>less</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Warranty</td>\n",
       "      <td>Product Registration and Warranty</td>\n",
       "      <td>Need to register the product with the brand fo...</td>\n",
       "      <td>Product Registration and Warranty -&gt; Need to r...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Electric Kettle</td>\n",
       "      <td>medium</td>\n",
       "      <td>junior</td>\n",
       "      <td>handles customer inquiries independently, poss...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Order</td>\n",
       "      <td>Order Confirmation and Status</td>\n",
       "      <td>Tracking/Shipping Updates</td>\n",
       "      <td>Order Confirmation and Status -&gt; Tracking/Ship...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Air Cooler</td>\n",
       "      <td>less</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Order</td>\n",
       "      <td>Order Confirmation and Status</td>\n",
       "      <td>Confirming order status</td>\n",
       "      <td>Order Confirmation and Status -&gt; Confirming or...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smart Band</td>\n",
       "      <td>less</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Customer: Hi, I'm calling to inquire about my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cancellations and returns</td>\n",
       "      <td>Pickup and Shipping</td>\n",
       "      <td>Pickup process</td>\n",
       "      <td>Pickup and Shipping -&gt; Pickup process</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>less</td>\n",
       "      <td>junior</td>\n",
       "      <td>handles customer inquiries independently, poss...</td>\n",
       "      <td>Customer: Hi, I would like to know about the p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  issue_area                         issue_category  \\\n",
       "0          Login and Account  Account Reactivation and Deactivation   \n",
       "1                   Warranty      Product Registration and Warranty   \n",
       "2                      Order          Order Confirmation and Status   \n",
       "3                      Order          Order Confirmation and Status   \n",
       "4  Cancellations and returns                    Pickup and Shipping   \n",
       "\n",
       "                                  issue_sub_category  \\\n",
       "0                   Reactivating an inactive account   \n",
       "1  Need to register the product with the brand fo...   \n",
       "2                          Tracking/Shipping Updates   \n",
       "3                            Confirming order status   \n",
       "4                                     Pickup process   \n",
       "\n",
       "                         issue_category_sub_category customer_sentiment  \\\n",
       "0  Account Reactivation and Deactivation -> React...           negative   \n",
       "1  Product Registration and Warranty -> Need to r...            neutral   \n",
       "2  Order Confirmation and Status -> Tracking/Ship...            neutral   \n",
       "3  Order Confirmation and Status -> Confirming or...           positive   \n",
       "4              Pickup and Shipping -> Pickup process            neutral   \n",
       "\n",
       "  product_category product_sub_category issue_complexity  \\\n",
       "0       Appliances       Microwave Oven             less   \n",
       "1       Appliances      Electric Kettle           medium   \n",
       "2       Appliances           Air Cooler             less   \n",
       "3      Electronics           Smart Band             less   \n",
       "4      Electronics               Tablet             less   \n",
       "\n",
       "  agent_experience_level                        agent_experience_level_desc  \\\n",
       "0            experienced  confidently handles complex customer issues, e...   \n",
       "1                 junior  handles customer inquiries independently, poss...   \n",
       "2            experienced  confidently handles complex customer issues, e...   \n",
       "3            experienced  confidently handles complex customer issues, e...   \n",
       "4                 junior  handles customer inquiries independently, poss...   \n",
       "\n",
       "                                        conversation  \n",
       "0  Agent: Thank you for calling BrownBox customer...  \n",
       "1  Agent: Thank you for calling BrownBox customer...  \n",
       "2  Agent: Thank you for calling BrownBox Customer...  \n",
       "3  Customer: Hi, I'm calling to inquire about my ...  \n",
       "4  Customer: Hi, I would like to know about the p...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db5c237a-455d-429c-8286-040be79546f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Cancellations and returns',\n",
       " 1: 'Login and Account',\n",
       " 2: 'Order',\n",
       " 3: 'Shipping',\n",
       " 4: 'Shopping',\n",
       " 5: 'Warranty'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(df['issue_area'].astype('category').cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2bc19a8-aa88-4e12-8781-b04244dd4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the inference data from CSV\n",
    "inference_df = pd.read_csv(\"inference_488.csv\")\n",
    "\n",
    "# Assuming the conversation text is stored in a column named \"Text\"\n",
    "# (adjust the column name if necessary)\n",
    "sample_conversations = inference_df[\"conversation\"].tolist()\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "def infer_intent(conversation_text, model, tokenizer, max_length=256, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Performs inference on a single conversation text.\n",
    "    \n",
    "    Args:\n",
    "      conversation_text (str): The raw conversation text.\n",
    "      model: The trained LoRA-wrapped model.\n",
    "      tokenizer: The tokenizer used during training.\n",
    "      max_length (int): Maximum sequence length (must match training).\n",
    "      device (str): Device to run inference on (e.g., \"cpu\").\n",
    "      \n",
    "    Returns:\n",
    "      predicted_label (int): The predicted label index.\n",
    "    \"\"\"\n",
    "    # Ensure model is on the right device and in eval mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\n",
    "        conversation_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Move inputs to the same device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Disable gradients for inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optionally, print the first few rows to verify the data\n",
    "# print(inference_df.head())\n",
    "\n",
    "# If you have a label mapping dictionary defined (from training), e.g.:\n",
    "# label_mapping = dict(enumerate(df['issue_area'].astype('category').cat.categories))\n",
    "\n",
    "label_mapping= { \n",
    "                 0: 'Cancellations and returns',\n",
    "                 1: 'Login and Account',\n",
    "                 2: 'Order',\n",
    "                 3: 'Shipping',\n",
    "                 4: 'Shopping',\n",
    "                 5: 'Warranty'\n",
    "                }\n",
    "\n",
    "# Create an inverted mapping: string to numeric\n",
    "inverted_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Run inference on each sample conversation using your wrapped model\n",
    "# Note: Make sure that wrapped_model and tokenizer have been loaded (as during training)\n",
    "predictions = []\n",
    "for idx, conversation in enumerate(sample_conversations):\n",
    "    predicted_label = infer_intent(conversation, wrapped_model, tokenizer, max_length=256, device=\"cpu\")\n",
    "    predictions.append(predicted_label)\n",
    "    # print(f\"Conversation {idx+1}:\")\n",
    "    # print(conversation)\n",
    "    # print(\"Predicted Label:\", predicted_label)\n",
    "    # print(\"Predicted Intent:\", label_mapping.get(predicted_label, \"Unknown\"))\n",
    "    # print(\"-\" * 80)\n",
    "\n",
    "# Optionally, add the predictions back to the DataFrame and save to a new CSV\n",
    "inference_df[\"Predicted_Label\"] = predictions  # Removed the trailing comma\n",
    "inference_df[\"Predicted_Intent\"] = inference_df[\"Predicted_Label\"].map(label_mapping)\n",
    "inference_df.to_csv(\"inference_with_predictions_50.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d354ef1-75ec-4232-a5d6-c93e40eeb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 88.32%\n"
     ]
    }
   ],
   "source": [
    "# Create an inverted mapping: string to numeric\n",
    "# inverted_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "# Convert the ground truth issue areas to numeric using the inverted mapping\n",
    "ground_truth_numeric = inference_df[\"issue_area\"].map(inverted_label_mapping)\n",
    "\n",
    "# Compute overall accuracy\n",
    "acc = accuracy_score(ground_truth_numeric, predictions)\n",
    "print(\"Total Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1983dc0-a632-4220-8c23-83266ad38295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a57995-e653-485b-9e64-935a6ba5667a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9f7ff-394e-486c-bf7e-5097b201e396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26562f-bf10-4244-9c81-5fe6131dfb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74a7fe22-c7de-4c47-9d09-062359a381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Cancellations and returns',\n",
       " 1: 'Login and Account',\n",
       " 2: 'Order',\n",
       " 3: 'Shipping',\n",
       " 4: 'Shopping',\n",
       " 5: 'Warranty'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(df['issue_area'].astype('category').cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bf60dad-7c45-4d16-a362-05ea00432262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 83.61%\n"
     ]
    }
   ],
   "source": [
    "# Create an inverted mapping: string to numeric\n",
    "# inverted_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "# Convert the ground truth issue areas to numeric using the inverted mapping\n",
    "ground_truth_numeric = inference_df[\"issue_area\"].map(inverted_label_mapping)\n",
    "\n",
    "# Compute overall accuracy\n",
    "acc = accuracy_score(ground_truth_numeric, predictions)\n",
    "print(\"Total Accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81ac7637-4986-475a-a033-24503e8d93a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_area\n",
       "Cancellations and returns    139\n",
       "Order                        132\n",
       "Login and Account             74\n",
       "Shopping                      57\n",
       "Warranty                      51\n",
       "Shipping                      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45f11e-a0ba-4db2-b38d-2fd4a53728c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"./exp_4_87_30epc_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1993a-09a8-4344-a588-cc8085b7778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TimeCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch_times = []\n",
    "    \n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        # Record the start time of the epoch\n",
    "        self.epoch_start_time = time.time()\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # Compute the duration of the epoch\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {state.epoch:.2f} finished in {epoch_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb53aba-a91c-429a-96da-d3d7b83ad890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of your custom callback\n",
    "time_callback = TimeCallback()\n",
    "\n",
    "# Create your Trainer with the callback\n",
    "trainer = Trainer(\n",
    "    model=wrapped_model,  # Use your wrapped model for training\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[time_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb1f11-74f6-4dca-a3ae-7bf871f5ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure total training time\n",
    "train_start = time.time()\n",
    "trainer.train()\n",
    "total_train_time = time.time() - train_start\n",
    "print(f\"Total Training Time: {total_train_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec1694e-2bcb-45bf-8645-2ee06228266f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4fd3edb6-a3af-4215-9491-b19849a59d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f802aab-358c-4a12-b10f-f8a0b106e739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21be333f-7c8d-4f99-8f48-a3e7b3dac387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation 1:\n",
      "Agent: Thank you for calling XYZ customer support. My name is Alex. How may I assist you today?\n",
      "Customer: Hi Alex, I placed an order two weeks ago and haven't received it yet. Could you check its status for me?\n",
      "Agent: Certainly. May I have your order number, please?\n",
      "Customer: Yes, it's 123456.\n",
      "Agent: Thank you. I see that there is a delay due to logistics. We are working to resolve it and will update you shortly.\n",
      "Predicted Label: 2\n",
      "Predicted Intent: Order\n",
      "--------------------------------------------------------------------------------\n",
      "Conversation 2:\n",
      "Agent: Hello, thank you for contacting our support. This is Lisa speaking. How can I help you today?\n",
      "Customer: Hi Lisa, I would like to cancel my order as I no longer need the product.\n",
      "Agent: I’m sorry to hear that. Could you please provide your order number?\n",
      "Customer: It’s 654321.\n",
      "Agent: Thank you. I have processed the cancellation and you will receive a refund within 3-5 business days.\n",
      "Predicted Label: 2\n",
      "Predicted Intent: Order\n",
      "--------------------------------------------------------------------------------\n",
      "Conversation 3:\n",
      "Agent: Good day, thank you for calling our support center. How may I assist you?\n",
      "Customer: Hello, I received an email about a shipping delay, but I haven’t seen any update on my package status.\n",
      "Agent: I apologize for the inconvenience. Could you please share your tracking number?\n",
      "Customer: Sure, it's ABC123XYZ.\n",
      "Agent: Thank you. It appears that there was a delay at the distribution center. Your package should arrive soon.\n",
      "Predicted Label: 2\n",
      "Predicted Intent: Order\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "def infer_intent(conversation_text, model, tokenizer, max_length=256, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Performs inference on a single conversation text.\n",
    "    \n",
    "    Args:\n",
    "      conversation_text (str): The raw conversation text.\n",
    "      model: The trained LoRA-wrapped model.\n",
    "      tokenizer: The tokenizer used during training.\n",
    "      max_length (int): Maximum sequence length (must match training).\n",
    "      device (str): Device to run inference on (e.g., \"cpu\").\n",
    "      \n",
    "    Returns:\n",
    "      predicted_label (int): The predicted label index.\n",
    "    \"\"\"\n",
    "    # Ensure model is on the right device and in eval mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\n",
    "        conversation_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Move inputs to the same device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Disable gradients for inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_label\n",
    "\n",
    "# Sample conversation data for inference\n",
    "sample_conversations = [\n",
    "\n",
    "    \"\"\"Agent: Thank you for calling XYZ customer support. My name is Alex. How may I assist you today?\n",
    "Customer: Hi Alex, I placed an order two weeks ago and haven't received it yet. Could you check its status for me?\n",
    "Agent: Certainly. May I have your order number, please?\n",
    "Customer: Yes, it's 123456.\n",
    "Agent: Thank you. I see that there is a delay due to logistics. We are working to resolve it and will update you shortly.\"\"\",\n",
    "\n",
    "\n",
    "    \"\"\"Agent: Hello, thank you for contacting our support. This is Lisa speaking. How can I help you today?\n",
    "Customer: Hi Lisa, I would like to cancel my order as I no longer need the product.\n",
    "Agent: I’m sorry to hear that. Could you please provide your order number?\n",
    "Customer: It’s 654321.\n",
    "Agent: Thank you. I have processed the cancellation and you will receive a refund within 3-5 business days.\"\"\",\n",
    "\n",
    "\n",
    "    \"\"\"Agent: Good day, thank you for calling our support center. How may I assist you?\n",
    "Customer: Hello, I received an email about a shipping delay, but I haven’t seen any update on my package status.\n",
    "Agent: I apologize for the inconvenience. Could you please share your tracking number?\n",
    "Customer: Sure, it's ABC123XYZ.\n",
    "Agent: Thank you. It appears that there was a delay at the distribution center. Your package should arrive soon.\"\"\"\n",
    "]\n",
    "\n",
    "# Example: Run inference on each sample conversation\n",
    "for idx, conversation in enumerate(sample_conversations):\n",
    "    predicted_label = infer_intent(conversation, wrapped_model, tokenizer, max_length=256, device=\"cpu\")\n",
    "    \n",
    "    # If you have a mapping from label indices to intent names, you can display the intent.\n",
    "    # For example, if you computed the mapping during preprocessing:\n",
    "    label_mapping = dict(enumerate(df['issue_area'].astype('category').cat.categories))\n",
    "\n",
    "    print(f\"Conversation {idx+1}:\")\n",
    "    print(conversation)\n",
    "    print(\"Predicted Label:\", predicted_label)\n",
    "    print(\"Predicted Intent:\", label_mapping.get(predicted_label, \"Unknown\"))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c883e4c-4b00-488c-86f8-dd24aea24e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970848d-9603-4b06-bd43-97acc6154fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733d48c-ea98-4f31-8be8-b4c9e47328d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bd36d-7008-4270-81c4-65c9e8eb91a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
